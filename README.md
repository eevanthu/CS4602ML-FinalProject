# CS4602ML-FinalProject: TSMC (2330) Stock Movement Prediction
# ğŸ“ˆ Stacking Ensemble Architecture for Financial Forecasting

This project implements a robust machine learning pipeline to predict the price movement (Up/Down) of TSMC (2330). By leveraging a multi-model **Stacking Ensemble** approach, we combine the strengths of distance-based algorithms, tree-based models, and deep learning architectures to capture complex market dynamics.

---

## ğŸšª Quick Navigation (å‚³é€é–€)

| Resource | Description | Link |
| :--- | :--- | :--- |
| **ğŸŒ Website Gallery** | Curated financial data sources & research sites | [ğŸ”— View Sites](./website.md) |
| **ğŸ“ Data Repository** | Raw and processed datasets for 2330 forecasting | [ğŸ”— Explore Data](./data/) |
| **ğŸ“ CheckPoints** | Project milestones and phase-wise reports | [ğŸ”— CheckPoints](./checkpoint/) |
| **ğŸ“Š Result Hub** | Exported prediction probabilities| [ğŸ”— View Results](./data/results/) |

---

## ğŸ—‚ï¸ Project Structure

The repository is organized into four core functional domains:

```text
.
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ backtest/            # Trading strategy & financial performance evaluation
â”‚   â”‚   â”œâ”€â”€ backtest6.py     # Core backtesting engine
â”‚   â”‚   â””â”€â”€ README.md        # Performance metrics (Sharpe, MDD, Returns)
â”‚   â”œâ”€â”€ models/              # Base Learners (The Model Zoo)
â”‚   â”‚   â”œâ”€â”€ KNN/             # K-Nearest Neighbors (Cluster-Augmented)
â”‚   â”‚   â”œâ”€â”€ LSTM/            # Long Short-Term Memory (Temporal Dependency)
â”‚   â”‚   â”œâ”€â”€ RandomForest/    # Ensemble Tree-based model
â”‚   â”‚   â”œâ”€â”€ XGBoost/         # Gradient Boosting Machine
â”‚   â”‚   â”œâ”€â”€ NN/              # Multi-layer Perceptron (MLP)
â”‚   â”‚   â””â”€â”€ NaiveBayes/      # Statistical baseline
â”‚   â”œâ”€â”€ preprocess/          # ETL & Feature Engineering pipeline
â”‚   â”‚   â”œâ”€â”€ data_download.ipynb
â”‚   â”‚   â””â”€â”€ preprocess.ipynb # Multi-dimensional indicator generation
â”‚   â””â”€â”€ stack/               # Meta-learner for final ensemble aggregation
â”‚       â””â”€â”€ stacking.ipynb   # Meta-feature fusion & final prediction
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/           # Standardized features (Post-ETL)
â”‚   â””â”€â”€ raw/                 # Source signals (2330, ADR, Global Indices)
â””â”€â”€ results/                 # Probabilistic Meta-features for Stacking

ğŸš€ Key Technical Features
1. Multi-dimensional Feature Engineering
We integrate 100+ technical indicators, macro-market data, and interdependency signals:

Technical: MA, RSI, MACD, K/D, Bollinger Bands.

Global Macro: S&P 500, NASDAQ, SOX (Philly Semiconductor), DJI.

Cross-Market: TSMC ADR price movements and VIX volatility.

2. Advanced Preprocessing Pipeline
Temporal Alignment: Corrects for U.S./Taiwan market time differences (Shift-1) to ensure Zero Data Leakage.

Cluster Augmentation: Using K-Means to identify market regimes, providing the KNN model with logical environment anchors.

Smart Imputation: Categorical handling of missing values (Binary vs. Continuous) to maintain time-series integrity.

3. Stacking Ensemble Mechanism
Base Learners: A diverse "Zoo" of models trained to capture different market anomalies.

Rolling Forecast: Models are trained annually (2020â€“2024) to generate out-of-sample predictions.

Meta-Learner: The final Stacking layer learns how to dynamically weight each model's probability output based on historical accuracy.

ğŸ› ï¸ Getting Started
Installation
Each module is designed with self-contained dependencies. It is recommended to use a virtual environment:

# 1. Clone the repository
git clone [https://github.com/your-repo/CS4602ML-FinalProject.git](https://github.com/your-repo/CS4602ML-FinalProject.git)

# 2. Setup environment for a specific module (e.g., KNN)
cd code/models/KNN
pip install -r requirements.txt

Execution Order
Preprocessing: Run code/preprocess/preprocess.ipynb to build the feature matrix.

Base Training: Execute notebooks in code/models/ to populate the results/ folder.

Ensemble: Run code/stack/stacking.ipynb to fuse base model predictions.

Evaluation: Use code/backtest/backtest6.py to generate the final investment report.

ğŸ“ˆ Performance Summary
Results are updated per milestone in the CheckPoint folder.

Disclaimer: This project is for educational purposes only. Financial markets involve high risk; predictions are based on historical patterns and do not guarantee future performance.
