{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab35f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc04041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Base Models Accuracy:\n",
      "Model      | Train Acc    | Test Acc    \n",
      "----------------------------------------\n",
      "KNN        | 0.5572       | 0.6505      \n",
      "LSTM       | 0.5736       | 0.6262      \n",
      "XG         | 0.5005       | 0.5631      \n",
      "----------------------------------------\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best CV Accuracy: 0.6179082419192499\n",
      "Stacking Accuracy on Test Set: 0.6796\n",
      "\n",
      "Feature Importance:\n",
      "   Model    Weight\n",
      "0   KNN  0.527925\n",
      "1  LSTM  0.259847\n",
      "2    XG  0.212228\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and preprocess the dataset\n",
    "file_path = 'stacking.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert Date column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Split data into training (2021â€“2024) and testing (2025) sets\n",
    "train_df = df[(df['Date'].dt.year >= 2021) & (df['Date'].dt.year <= 2024)]\n",
    "test_df = df[df['Date'].dt.year == 2025]\n",
    "\n",
    "# Define feature columns (base model predictions) and target column\n",
    "feature_columns = ['KNN', 'LSTM','XG'] # choose the model\n",
    "target_column = 'movement'\n",
    "\n",
    "X_train = train_df[feature_columns]\n",
    "y_train = train_df[target_column]\n",
    "X_test = test_df[feature_columns]\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "# 2. Evaluate accuracy of each base model\n",
    "print(\"\\nBase Models Accuracy:\")\n",
    "base_model_scores = {}\n",
    "print(f\"{'Model':<10} | {'Train Acc':<12} | {'Test Acc':<12}\")\n",
    "print(\"-\"*40)\n",
    "for col in feature_columns:\n",
    "    # Convert predicted probabilities to binary labels\n",
    "    train_pred = train_df[col].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    test_pred = test_df[col].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "    \n",
    "\t# Compute accuracy on training and testing sets\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, test_pred)\n",
    "    \n",
    "    base_model_scores[col] = test_acc\n",
    "    print(f\"{col:<10} | {train_acc:<12.4f} | {test_acc:<12.4f}\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "# 3. Define hyperparameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [1, 2, 3],\n",
    "    'learning_rate': [0.01, 0.02, 0.005]\n",
    "}\n",
    "\n",
    "# 4. Create XGBoost classifier and apply GridSearchCV\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "# Perform 3-fold cross-validation grid search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',   \n",
    "    cv=3,                \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Accuracy:\", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the best stacking model on test set\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# extract predict class labels and probabilities\n",
    "y_pred_stack = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute test accuracy\n",
    "stacking_acc = accuracy_score(y_test, y_pred_stack)\n",
    "print(f\"Stacking Accuracy on Test Set: {stacking_acc:.4f}\")\n",
    "\n",
    "# Display feature importance of base models\n",
    "importance_df = pd.DataFrame({\n",
    "    'Model': feature_columns,\n",
    "    'Weight': best_model.feature_importances_\n",
    "}).sort_values(by='Weight', ascending=False)\n",
    "print(\"\\nFeature Importance:\\n\", importance_df)\n",
    "\n",
    "\n",
    "# Store original predicted probability\n",
    "output_df = test_df[['Date']].copy()\n",
    "output_df['Probability'] = y_pred_proba\n",
    "output_df['Probability'] = (y_pred_proba - np.min(y_pred_proba)) / (np.max(y_pred_proba) - np.min(y_pred_proba))\n",
    "output_df['Actual'] = y_test.values\n",
    "\n",
    "output_df.to_csv('stacking_pred_prob.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
